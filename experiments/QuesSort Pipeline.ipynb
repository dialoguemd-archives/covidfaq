{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions Clustering - English\n",
    "\n",
    "## Expected\n",
    "Questions to be sorted out such that the response to the whole cluster is same.\n",
    "\n",
    "<!--### To Do-->\n",
    "Author: Sunanda Bansal  \n",
    "Organization: Dataperformers  \n",
    "License: CC BY-NC  \n",
    "Date: 24 Mar, 2020 (Start)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import regex\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import scipy\n",
    "import socket\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import Normalizer   \n",
    "from sklearn import metrics   \n",
    "from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics.pairwise import paired_distances as sklearn_paired_distances\n",
    "\n",
    "# Plotting\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# importing personal development helper classes\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define variables here\n",
    "\n",
    "Mostly the code will be intended to use with arguments that can be passed in comman line, but jupyter notebook doesn't handle `argparse` well, so the Args class is a temporary way to write the code assumming the variables to be an attribute of an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        # The very big scraped file, give absolute path, outside the repo\n",
    "        # self.filename = \"query_result_2020-03-27T19_12_30.866993Z.csv\"\n",
    "        self.filename = \"data_dump_2020-04-14.csv\"\n",
    "        \n",
    "        # path to the file\n",
    "        self.dataset = f\"data/{self.filename}\"    \n",
    "        \n",
    "        # suffix used to create\n",
    "        self.suffix = \"_\".join([word for word in self.filename.split(\"_\") if not word.isalpha()])[:-4]\n",
    "        self.vector_mode = \"tfidf\"\n",
    "        self.n_topics = 230\n",
    "        self.dist_thresh = 1.5\n",
    "        self.lang = \"en\"\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary is used to translate old labels to new labels minimizing modifications required for the moment\n",
    "new_labels = {\n",
    "                \"about\": \"covid-what\",\n",
    "                \"animals\": \"covid-animals\",\n",
    "                \"caution\": \"personal-caution\",\n",
    "                \"dangerisk\": \"covid-contagious\",\n",
    "                \"diff\": \"covid-versus\",\n",
    "                \"future\": \"situation-future\",\n",
    "                \"guideme\": \"personal-whatif\",\n",
    "                \"incubation\": \"covid-incubation\",\n",
    "                \"infection\": \"covid-infection\",\n",
    "                \"isolation\": \"personal-isolation\",\n",
    "                \"lockdown\": \"situation-lockdown\",\n",
    "                \"nextsteps\": \"personal-symptoms\",\n",
    "                \"past\": \"situation-past\",\n",
    "                \"recover\": \"covid-recovery\",\n",
    "                \"statistics\": \"situation-stats\",\n",
    "                \"symptom\": \"covid-symptoms\",\n",
    "                \"test\": \"personal-testing\",\n",
    "                \"transmission\": \"covid-transmission\",\n",
    "                \"treatment\": \"covid-med\",\n",
    "                \"unclassified\": \"unclassified\",\n",
    "                \"virusfight\": \"covid-fight\",\n",
    "                \"viruskill\": \"covid-kill\",\n",
    "                \"viruslife\": \"covid-life\"\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable (FALSE) displaying warnings from the OpenMP* run-time library during program execution.\n",
    "os.environ['KMP_WARNINGS'] = \"FALSE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex functions\n",
    "def surrounding(word,area=2):\n",
    "    # A funtion, yet to be defined, that can be used to extract text around keywords\n",
    "    return\n",
    "\n",
    "def fuzzy_match(word,pattern):\n",
    "    '''\n",
    "        Fuzzy matching function to be used with .apply() of pandas\n",
    "\n",
    "        Reason - Fuzzy matching is available in regex package, not in re package, \n",
    "        therefore fuzzy matching is not a part of pandas string matching functions\n",
    "    '''\n",
    " \n",
    "    if regex.search(pattern, word, re.IGNORECASE):\n",
    "        return True\n",
    "    else:\n",
    "        return False    \n",
    "    \n",
    "# Language Detection\n",
    "from langdetect import detect\n",
    "def detect_lang(text):\n",
    "    # Used to detect language of the question\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return \"unidentifiable\"   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Lanuage Proprocessing Functions\n",
    "   \n",
    "Preprocessing done -\n",
    "   1. Normalizing accents  \n",
    "   2. Removing non alphabetic characters  \n",
    "   3. Casefolding  \n",
    "\n",
    "Preprocessing not done -\n",
    "   1. Stopword removal - For questions, stopwords are essential and thus are retained\n",
    "   2. Stemming - For rule based analysis it might be useful to keep the words as they are, for LSA, the questions don't have enough variation in content to benefit for stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import unidecode\n",
    "\n",
    "# Regular expression to select all that is not alphabet\n",
    "# @maybe allow numbers as well\n",
    "alpha_regex = re.compile('[^a-zA-Z]')\n",
    "\n",
    "from nltk.corpus import stopwords as sw\n",
    "if args.lang == \"en\": stopwords = sw.words('english')\n",
    "if args.lang == \"fr\": stopwords = sw.words('french')\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "if args.lang == \"en\": stemmer = SnowballStemmer(\"english\")\n",
    "if args.lang == \"fr\": stemmer = SnowballStemmer(\"french\")\n",
    "\n",
    "def tokenize(text):\n",
    "    '''\n",
    "        1. Normalized accents\n",
    "        2. Splits at non alpbhaetic character (@maybe need to revisit for french text)\n",
    "        3. Caasefolds\n",
    "    '''    \n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            # Handle french accents in text\n",
    "            word = unidecode.unidecode(word)\n",
    "            \n",
    "            # Split at every non alphabet character occurrence\n",
    "            clean_words = alpha_regex.sub(' ', word).split()\n",
    "            \n",
    "            # Casefold\n",
    "            tokens.extend([word.lower() for word in clean_words])\n",
    "    \n",
    "    # Return tokens\n",
    "    return tokens\n",
    "\n",
    "def stem(word):\n",
    "    return stemmer.stem(word).strip()\n",
    "\n",
    "def preprocess(text):    \n",
    "    tokenized = tokenize(text)\n",
    "    # cleaned = [word for word in tokenized if word not in stopwords and word != '']\n",
    "    # stemmed = [stem(word) for word in cleaned]\n",
    "    return ' '.join(tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will add later, right now, leaving it to the utils doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 5005 documents\n",
      "Dataset has 2023 english documents\n"
     ]
    }
   ],
   "source": [
    "# Read dataset\n",
    "dataset = pd.read_csv(f\"data/{args.filename}\")\n",
    "print(f\"Dataset has {len(dataset)} documents\")\n",
    "\n",
    "# Detect Language\n",
    "dataset[\"detected_lang\"] = dataset.question.apply(detect_lang)\n",
    "\n",
    "# Filter questions by language\n",
    "dataset = dataset[dataset.detected_lang == args.lang]\n",
    "\n",
    "# Preprocess questions\n",
    "dataset[\"text\"] = dataset.question.apply(preprocess)\n",
    "print(f\"Dataset has {len(dataset)} english documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is Dialogue's position on sick notes?</td>\n",
       "      <td>what is dialogue s position on sick notes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are Dialogue services?</td>\n",
       "      <td>what are dialogue services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Should I practice social distancing?</td>\n",
       "      <td>should i practice social distancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'd love to know how long I can be contagious?</td>\n",
       "      <td>i d love to know how long i can be contagious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Get I get infected from a dog?</td>\n",
       "      <td>get i get infected from a dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Someone from quarantaine came to my office and...</td>\n",
       "      <td>someone from quarantaine came to my office and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is the difference between a pandemic &amp; ep...</td>\n",
       "      <td>what is the difference between a pandemic epid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>If you start showing flu symptoms should you c...</td>\n",
       "      <td>if you start showing flu symptoms should you c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Can I go for a run? Does running/exercise comp...</td>\n",
       "      <td>can i go for a run does running exercise compr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>If I think I have symptoms of COVID19 should I...</td>\n",
       "      <td>if i think i have symptoms of covid should i g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I had an asthma attack when I was young, but d...</td>\n",
       "      <td>i had an asthma attack when i was young but di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mental health</td>\n",
       "      <td>mental health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>What are the symptoms? Is vomiting one of them ?</td>\n",
       "      <td>what are the symptoms is vomiting one of them</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>if i think i have it, should i got get tested</td>\n",
       "      <td>if i think i have it should i got get tested</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>is covid-19 dangerous</td>\n",
       "      <td>is covid dangerous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>something something this is jared testing</td>\n",
       "      <td>something something this is jared testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>What range is the fever at normally if COVID-1...</td>\n",
       "      <td>what range is the fever at normally if covid s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>I got the flu two weeks ago and are getting sy...</td>\n",
       "      <td>i got the flu two weeks ago and are getting sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Is it safe to go outside for a walk (social di...</td>\n",
       "      <td>is it safe to go outside for a walk social dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Should I stay home ?</td>\n",
       "      <td>should i stay home</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0          What is Dialogue's position on sick notes?   \n",
       "1                         What are Dialogue services?   \n",
       "2               Should I practice social distancing?    \n",
       "4      I'd love to know how long I can be contagious?   \n",
       "7                      Get I get infected from a dog?   \n",
       "8   Someone from quarantaine came to my office and...   \n",
       "9   What is the difference between a pandemic & ep...   \n",
       "13  If you start showing flu symptoms should you c...   \n",
       "15  Can I go for a run? Does running/exercise comp...   \n",
       "16  If I think I have symptoms of COVID19 should I...   \n",
       "18  I had an asthma attack when I was young, but d...   \n",
       "19                                      mental health   \n",
       "27   What are the symptoms? Is vomiting one of them ?   \n",
       "28      if i think i have it, should i got get tested   \n",
       "31                              is covid-19 dangerous   \n",
       "35          something something this is jared testing   \n",
       "36  What range is the fever at normally if COVID-1...   \n",
       "42  I got the flu two weeks ago and are getting sy...   \n",
       "45  Is it safe to go outside for a walk (social di...   \n",
       "51                               Should I stay home ?   \n",
       "\n",
       "                                                 text  \n",
       "0           what is dialogue s position on sick notes  \n",
       "1                          what are dialogue services  \n",
       "2                 should i practice social distancing  \n",
       "4       i d love to know how long i can be contagious  \n",
       "7                       get i get infected from a dog  \n",
       "8   someone from quarantaine came to my office and...  \n",
       "9   what is the difference between a pandemic epid...  \n",
       "13  if you start showing flu symptoms should you c...  \n",
       "15  can i go for a run does running exercise compr...  \n",
       "16  if i think i have symptoms of covid should i g...  \n",
       "18  i had an asthma attack when i was young but di...  \n",
       "19                                      mental health  \n",
       "27      what are the symptoms is vomiting one of them  \n",
       "28       if i think i have it should i got get tested  \n",
       "31                                 is covid dangerous  \n",
       "35          something something this is jared testing  \n",
       "36  what range is the fever at normally if covid s...  \n",
       "42  i got the flu two weeks ago and are getting sy...  \n",
       "45  is it safe to go outside for a walk social dis...  \n",
       "51                                 should i stay home  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[[\"question\",\"text\"]][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[(dataset.language != \"en\") & (dataset.detected_lang == \"en\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[(dataset.language == \"en\") & (dataset.detected_lang != \"en\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules\n",
    "Note: The order of these rules matters in resolving conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics\n",
    "dataset[\"statistics\"] = (\n",
    "                        dataset.text.str.contains(\"cases\",case=False)|\n",
    "                        dataset.text.str.contains(\"death\",case=False)|\n",
    "                        dataset.text.str.contains(\"died\",case=False)|\n",
    "                        dataset.text.str.contains(\"mortality rate\",case=False)|\n",
    "                        dataset.text.str.contains(\"death rate\",case=False)|\n",
    "                        dataset.text.str.contains(\"deadly\",case=False)|\n",
    "                        dataset.text.str.contains(\"statistic\",case=False)|\n",
    "                        (\n",
    "                            dataset.text.str.contains(\"how\",case=False)&\n",
    "                            dataset.text.str.contains(\"many\",case=False)&\n",
    "                            dataset.text.str.contains(\"people\",case=False)\n",
    "                        )\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"animals\"] = (\n",
    "                        dataset.text.str.contains(r\"\\b(?:animal|bird|cat|dog)s?\\b\",case=False)\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"caution\"] = (\n",
    "                        dataset.text.str.contains(\"prevent\",case=False)|\n",
    "                        dataset.text.str.contains(\"protect\",case=False)|\n",
    "                        dataset.text.str.contains(\"precaution\",case=False)|\n",
    "                        dataset.text.str.contains(\"safety\",case=False)|\n",
    "                        (\n",
    "                            dataset.text.str.contains(\"keep\",case=False)&\n",
    "                            dataset.text.str.contains(\"safe\",case=False)\n",
    "                        )\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"viruslife\"] = (\n",
    "                            (\n",
    "                                dataset.text.apply(fuzzy_match, pattern=\"(?:covid){e<=2}\")|\n",
    "                                dataset.text.str.contains(\"corona\",case=False)|\n",
    "                                dataset.text.str.contains(\"virus\",case=False)\n",
    "                            )&\n",
    "                            (\n",
    "                                dataset.text.str.contains(\"live|stay|survive\",case=False)\n",
    "                            )&\n",
    "                            (\n",
    "                                dataset.text.str.contains(\"on\",case=False)\n",
    "                            )\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"viruskill\"] = (\n",
    "                            (\n",
    "                                dataset.text.apply(fuzzy_match, pattern=\"(?:covid){e<=2}\")|\n",
    "                                dataset.text.str.contains(\"corona\",case=False)|\n",
    "                                dataset.text.str.contains(\"virus\",case=False)\n",
    "                            )&\n",
    "                            (\n",
    "                                dataset.text.str.contains(\"kills\",case=False)\n",
    "                            )\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"virusfight\"] = (\n",
    "                            (\n",
    "                                (\n",
    "                                    dataset.text.apply(fuzzy_match, pattern=\"(?:covid){e<=2}\")|\n",
    "                                    dataset.text.str.contains(\"corona\",case=False)|\n",
    "                                    dataset.text.str.contains(\"virus\",case=False)\n",
    "                                )&\n",
    "                                (\n",
    "                                    dataset.text.str.contains(\"fight\",case=False)\n",
    "                                )&\n",
    "                                (\n",
    "                                    dataset.text.str.contains(\"help\",case=False)\n",
    "                                )\n",
    "                            )|\n",
    "                            (\n",
    "                                dataset.text.str.contains(\"mask\",case=False)|\n",
    "                                dataset.text.str.contains(\"glove\",case=False)\n",
    "                            )\n",
    "                        ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"treatment\"] = (\n",
    "                        dataset.text.str.contains(\"treatment\",case=False)|\n",
    "                        dataset.text.str.contains(\"cure\",case=False)|\n",
    "                        dataset.text.str.contains(\"vaccine\",case=False)|\n",
    "                        dataset.text.str.contains(\"medic\",case=False)\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"incubation\"] = (\n",
    "                        dataset.text.str.contains(\"incubate\",case=False)|\n",
    "                        dataset.text.str.contains(\"incubation\",case=False)\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"nextsteps\"] = (\n",
    "                        dataset.text.str.contains(\"i have\",case=False) \n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"guideme\"] = (\n",
    "                        dataset.text.str.contains(\"if\",case=False)\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[\"hospital\"] = (\n",
    "# #                         dataset.text.str.contains(r\"\\bgo\\b\",case=False)&\n",
    "#                         (\n",
    "#                             dataset.text.str.contains(\"hospital\",case=False)|                            \n",
    "#                             dataset.text.str.contains(r\"\\bER\\b\",case=False)\n",
    "#                         )\n",
    "#                     ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dos and Donts\n",
    "dataset[\"lockdown\"] = (\n",
    "                        (\n",
    "                            (\n",
    "                                dataset.text.str.contains(\"go (?:on|to|for|out)\",case=False)|\n",
    "                                dataset.text.str.contains(\"walk\",case=False)\n",
    "                            )&\n",
    "                            (\n",
    "                                dataset.text.str.contains(\"allow\",case=False)|\n",
    "                                dataset.text.str.contains(\"can\",case=False)|\n",
    "                                dataset.text.str.contains(\"ok|okay\",case=False)|\n",
    "                                dataset.text.str.contains(\"should|shall\",case=False)\n",
    "                            )\n",
    "                        )|\n",
    "                        (\n",
    "                            dataset.text.str.contains(\"lockdown\",case=False)|\n",
    "                            dataset.text.str.contains(r\"\\bopen\\b\",case=False)|\n",
    "                            dataset.text.str.contains(r\"\\bclose\",case=False)\n",
    "                        )\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"infection\"] = (\n",
    "                        dataset.text.str.contains(\"infected\",case=False)|\n",
    "                        dataset.text.str.contains(\"infection\",case=False)\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"diff\"] = (\n",
    "                        dataset.text.str.contains(\"diff\",case=False)|\n",
    "                        dataset.text.apply(fuzzy_match, pattern=\"(?:distinguish){e<=3}\")\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"recover\"] = (\n",
    "                        dataset.text.str.contains(\"recover\",case=False)\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"test\"] = (\n",
    "                        dataset.text.str.contains(\"tested\",case=False)|\n",
    "                        dataset.text.str.contains(\"test\",case=False)\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"isolation\"] = (\n",
    "                            dataset.text.str.contains(r\"\\bisolat\",case=False)|\n",
    "                            dataset.text.str.contains(r\"\\bsocial dist\",case=False)\n",
    "                        ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"dangerisk\"] = (\n",
    "                            dataset.text.str.contains(\"dangerous\",case=False)|\n",
    "                            dataset.text.str.contains(\"risk\",case=False)\n",
    "                        ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"transmission\"] = (\n",
    "                            dataset.text.str.contains(\"transmi\",case=False)|\n",
    "                            dataset.text.str.contains(\"contract\",case=False)|\n",
    "                            dataset.text.str.contains(\"spread\",case=False)|\n",
    "                            dataset.text.apply(fuzzy_match, pattern=\"(?:airborne){e<=3}\")\n",
    "                        ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuzzy Matching of 'Symptom' keyword (accounting for spelling errors)\n",
    "dataset[\"symptom\"] = (\n",
    "                        dataset.text.apply(fuzzy_match, pattern=\"(?:symptom){1<=e<=3}\")\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"about\"] = (\n",
    "                        (\n",
    "                            dataset.text.apply(fuzzy_match, pattern=\"(?:whats|what (?:is|s))\")\n",
    "                        ) & \n",
    "                        (\n",
    "                            dataset.text.apply(fuzzy_match, pattern=\"(?:covid){e<=2}\")|\n",
    "                            dataset.text.str.contains(\"corona\",case=False)\n",
    "                        )\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"future\"] = (\n",
    "                        (\n",
    "                            (\n",
    "                                dataset.text.str.contains(\"how\",case=False) &\n",
    "                                dataset.text.str.contains(\"long\",case=False)\n",
    "                            )|\n",
    "                            dataset.text.str.contains(\"when\",case=False)\n",
    "                        )&\n",
    "                            dataset.text.str.contains(\"will\",case=False)&\n",
    "                        (\n",
    "                            dataset.text.str.contains(\"last|end|over|normal|done\",case=False)\n",
    "                        )\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"past\"] = (\n",
    "                        (\n",
    "                            dataset.text.str.contains(\"how|when|where\",case=False) \n",
    "                        )&\n",
    "                            dataset.text.str.contains(\"did\",case=False)&\n",
    "                        (\n",
    "                            dataset.text.str.contains(\"start|begin|began\",case=False)\n",
    "                        )\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename(columns=new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col_name for col_name in dataset.columns.values.tolist() if \"-\" in col_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['situation-stats',\n",
       " 'covid-animals',\n",
       " 'personal-caution',\n",
       " 'covid-life',\n",
       " 'covid-kill',\n",
       " 'covid-fight',\n",
       " 'covid-med',\n",
       " 'covid-incubation',\n",
       " 'personal-symptoms',\n",
       " 'personal-whatif',\n",
       " 'situation-lockdown',\n",
       " 'covid-infection',\n",
       " 'covid-versus',\n",
       " 'covid-recovery',\n",
       " 'personal-testing',\n",
       " 'personal-isolation',\n",
       " 'covid-contagious',\n",
       " 'covid-transmission',\n",
       " 'covid-symptoms',\n",
       " 'covid-what',\n",
       " 'situation-future',\n",
       " 'situation-past']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total number of classes/categories this question qualifies for\n",
    "dataset[\"total\"] = dataset[features].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total\n",
       "0      567.0\n",
       "1     1061.0\n",
       "2      285.0\n",
       "3       79.0\n",
       "4       23.0\n",
       "5        5.0\n",
       "6        2.0\n",
       "11       1.0\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describes how many questions quality for how many classes\n",
    "dataset.groupby(\"total\")[\"situation-stats\"].describe()[\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/designer1/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Set default value\n",
    "dataset[\"cluster\"] = \"unclassified\"\n",
    "\n",
    "# For single features\n",
    "for col in features:\n",
    "    dataset[\"cluster\"][(dataset.total == 1) & (dataset[col] == True)] = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/designer1/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Resolving multiple classes\n",
    "for col in features[::-1]:\n",
    "    dataset[\"cluster\"][(dataset.total > 1) & (dataset[col] == True)] = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rules based output saved to output/simple_2020-04-14_en.csv\n"
     ]
    }
   ],
   "source": [
    "# Saving the files\n",
    "path = f\"output/simple_{args.suffix}_{args.lang}.csv\"\n",
    "dataset.drop(features, axis=\"columns\").drop([\"text\",\"total\"], axis=\"columns\").to_csv(path)\n",
    "print(f\"Rules based output saved to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "covid-animals          14\n",
       "covid-contagious       47\n",
       "covid-fight            41\n",
       "covid-incubation       16\n",
       "covid-infection        66\n",
       "covid-kill              6\n",
       "covid-life             57\n",
       "covid-med              62\n",
       "covid-recovery         14\n",
       "covid-symptoms        228\n",
       "covid-transmission     56\n",
       "covid-versus            3\n",
       "covid-what            106\n",
       "personal-caution       55\n",
       "personal-isolation     38\n",
       "personal-symptoms     159\n",
       "personal-testing      101\n",
       "personal-whatif       190\n",
       "situation-future       19\n",
       "situation-lockdown     62\n",
       "situation-past          4\n",
       "situation-stats       103\n",
       "unclassified          553\n",
       "Name: question, dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clustering stats\n",
    "dataset.groupby(\"cluster\")[\"question\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length analysis for situations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA and AHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dataset[dataset.cluster==\"unclassified\"][[\"question\", \"cluster\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "stopwords_list = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def bulk_tokenizer(texts):\n",
    "#      return [[wn_lemmatizer.lemmatize(token) for token in nltk.word_tokenize(text)] for text in texts]\n",
    "     return [nltk.word_tokenize(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43 clusters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ahc_label\n",
       "31     2\n",
       "21     3\n",
       "36     3\n",
       "41     3\n",
       "40     4\n",
       "38     4\n",
       "34     4\n",
       "29     4\n",
       "23     4\n",
       "17     4\n",
       "39     5\n",
       "42     5\n",
       "4      6\n",
       "20     6\n",
       "3      7\n",
       "16     7\n",
       "19     7\n",
       "30     7\n",
       "26     7\n",
       "0      8\n",
       "15     8\n",
       "5      8\n",
       "28     8\n",
       "35     9\n",
       "27     9\n",
       "12    10\n",
       "8     10\n",
       "24    10\n",
       "14    11\n",
       "37    13\n",
       "33    13\n",
       "18    14\n",
       "9     15\n",
       "13    18\n",
       "25    18\n",
       "11    19\n",
       "1     21\n",
       "6     22\n",
       "7     22\n",
       "2     23\n",
       "10    26\n",
       "22    33\n",
       "32    36\n",
       "Name: question, dtype: int64"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.n_topics = 15\n",
    "args.dist_thresh = 0.7\n",
    "model = utils.text.representation.LSI(args, tokenizer=bulk_tokenizer)\n",
    "d[\"embedding\"] = model.generate_embedding(d.question, returnarray=False)\n",
    "\n",
    "# Cluster\n",
    "X = pd.DataFrame(d[\"embedding\"].values.tolist(), index= d.index).to_numpy()\n",
    "clustering = AgglomerativeClustering(n_clusters=None, compute_full_tree=True, distance_threshold=args.dist_thresh).fit(X)\n",
    "d[\"ahc_label\"] = clustering.labels_\n",
    "\n",
    "# Misc.\n",
    "args.n_clusters = len(d[\"ahc_label\"].unique())\n",
    "print(f\"Found {args.n_clusters} clusters\")\n",
    "d.groupby(\"ahc_label\")[\"question\"].count().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    43.000000\n",
       "mean     11.069767\n",
       "std       8.209737\n",
       "min       2.000000\n",
       "25%       5.000000\n",
       "50%       8.000000\n",
       "75%      14.500000\n",
       "max      36.000000\n",
       "Name: question, dtype: float64"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.groupby(\"ahc_label\")[\"question\"].count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for label in d.ahc_label.unique():\n",
    "#     print(f\"\\ncluster #{label}, count - {len(d[d.ahc_label==label])}\")\n",
    "#     print(d[d.ahc_label==label][:10].question.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.join(d[\"ahc_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AHC on top of rule based output saved to output/simpleLsa_15n0.7dt_2020-03-27T19_12_30.866993Z.csv\n"
     ]
    }
   ],
   "source": [
    "path = f\"output/simpleLsa_{args.n_topics}n{args.dist_thresh}dt_{args.suffix}.csv\"\n",
    "dataset.to_csv(path)\n",
    "print(f\"AHC on top of rule based output saved to {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
