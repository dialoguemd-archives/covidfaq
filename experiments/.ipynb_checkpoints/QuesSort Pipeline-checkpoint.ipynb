{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions Clustering\n",
    "\n",
    "## Expected\n",
    "Questions to be sorted out such that the response to the whole cluster is samel.\n",
    "\n",
    "<!--### To Do-->\n",
    "Author: Sunanda Bansal  \n",
    "Organization: Dataperformers  \n",
    "Date: 24 Mar, 2020 (Start)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import regex\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import scipy\n",
    "import socket\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import Normalizer   \n",
    "from sklearn import metrics   \n",
    "from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics.pairwise import paired_distances as sklearn_paired_distances\n",
    "\n",
    "# Plotting\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# importing personal development helper classes\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define variables here\n",
    "\n",
    "Mostly the code will be intended to use with arguments that can be passed in comman line, but jupyter notebook doesn't handle `argparse` well, so the Args class is a temporary way to write the code assumming the variables to be an attribute of an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        # The very big scraped file, give absolute path, outside the repo\n",
    "        # self.filename = \"query_result_2020-03-27T19_12_30.866993Z.csv\"\n",
    "        self.filename = \"data_dump_2020-04-14.csv\"\n",
    "        self.dataset = f\"data/{self.filename}\"        \n",
    "        self.suffix = \"_\".join([word for word in self.filename.split(\"_\") if not word.isalpha()])[:-4]\n",
    "        self.vector_mode = \"tfidf\"\n",
    "        self.n_topics = 230\n",
    "        self.dist_thresh = 1.5\n",
    "        self.lang = \"en\"\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = {\n",
    "                \"about\": \"covid-what\",\n",
    "                \"animals\": \"covid-animals\",\n",
    "                \"caution\": \"personal-caution\",\n",
    "                \"dangerisk\": \"covid-contagious\",\n",
    "                \"diff\": \"covid-versus\",\n",
    "                \"future\": \"situation-future\",\n",
    "                \"guideme\": \"personal-whatif\",\n",
    "                \"incubation\": \"covid-incubation\",\n",
    "                \"infection\": \"covid-infection\",\n",
    "                \"isolation\": \"personal-isolation\",\n",
    "                \"lockdown\": \"situation-lockdown\",\n",
    "                \"nextsteps\": \"personal-symptoms\",\n",
    "                \"past\": \"situation-past\",\n",
    "                \"recover\": \"covid-recovery\",\n",
    "                \"statistics\": \"situation-stats\",\n",
    "                \"symptom\": \"covid-symptoms\",\n",
    "                \"test\": \"personal-testing\",\n",
    "                \"transmission\": \"covid-transmission\",\n",
    "                \"treatment\": \"covid-med\",\n",
    "                \"unclassified\": \"unclassified\",\n",
    "                \"virusfight\": \"covid-fight\",\n",
    "                \"viruskill\": \"covid-kill\",\n",
    "                \"viruslife\": \"covid-life\"\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable (FALSE) displaying warnings from the OpenMP* run-time library during program execution.\n",
    "os.environ['KMP_WARNINGS'] = \"FALSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surrounding(word,area=2):\n",
    "    return\n",
    "\n",
    "def fuzzy_match(word,pattern):\n",
    "    if regex.search(pattern, word, re.IGNORECASE):\n",
    "        return True\n",
    "    else:\n",
    "        return False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import unidecode\n",
    "\n",
    "alpha_regex = re.compile('[^a-zA-Z]')\n",
    "\n",
    "from nltk.corpus import stopwords as sw\n",
    "if args.lang == \"en\": stopwords = sw.words('english')\n",
    "if args.lang == \"fr\": stopwords = sw.words('french')\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "if args.lang == \"en\": stemmer = SnowballStemmer(\"english\")\n",
    "if args.lang == \"fr\": stemmer = SnowballStemmer(\"french\")\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            word = unidecode.unidecode(word)\n",
    "            clean_words = alpha_regex.sub(' ', word).split()\n",
    "            tokens.extend([word.lower() for word in clean_words])\n",
    "    return tokens\n",
    "\n",
    "def stem(word):\n",
    "    return stemmer.stem(word).strip()\n",
    "\n",
    "def preprocess(text):    \n",
    "    tokenized = tokenize(text)\n",
    "    cleaned = [word for word in tokenized if word not in stopwords and word is not '']\n",
    "#     stemed = [stem(word) for word in cleaned]\n",
    "    #stemed = [stem(word) for word in tokenized]\n",
    "    #corpus[i] = ' '.join(tokenized)\n",
    "    return ' '.join(tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will add later, right now, leaving it to the utils doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 5005 documents\n",
      "Dataset has 2007 english documents\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(f\"data/{args.filename}\")\n",
    "print(f\"Dataset has {len(dataset)} documents\")\n",
    "\n",
    "# Language Detection\n",
    "def detect_lang(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return \"unidentifiable\"   \n",
    "\n",
    "from langdetect import detect\n",
    "dataset[\"detected_lang\"] = dataset.question.apply(detect_lang)\n",
    "\n",
    "dataset = dataset[dataset.detected_lang == args.lang]\n",
    "\n",
    "dataset[\"text\"] = dataset.question.apply(preprocess)\n",
    "print(f\"Dataset has {len(dataset)} english documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[(dataset.language != \"en\") & (dataset.detected_lang == \"en\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[(dataset.language == \"en\") & (dataset.detected_lang != \"en\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules\n",
    "Note: The order of these rules matters in resolving conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics\n",
    "dataset[\"statistics\"] = (\n",
    "                        dataset.text.str.contains(\"cases\",case=False)|\n",
    "                        dataset.text.str.contains(\"death\",case=False)|\n",
    "                        dataset.text.str.contains(\"died\",case=False)|\n",
    "                        dataset.text.str.contains(\"mortality rate\",case=False)|\n",
    "                        dataset.text.str.contains(\"death rate\",case=False)|\n",
    "                        dataset.text.str.contains(\"deadly\",case=False)|\n",
    "                        dataset.text.str.contains(\"statistic\",case=False)|\n",
    "                        (\n",
    "                            dataset.text.str.contains(\"how\",case=False)&\n",
    "                            dataset.text.str.contains(\"many\",case=False)&\n",
    "                            dataset.text.str.contains(\"people\",case=False)\n",
    "                        )\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"animals\"] = (\n",
    "                        dataset.text.str.contains(r\"\\b(?:animal|bird|cat|dog)s?\\b\",case=False)\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"caution\"] = (\n",
    "                        dataset.text.str.contains(\"prevent\",case=False)|\n",
    "                        dataset.text.str.contains(\"protect\",case=False)|\n",
    "                        dataset.text.str.contains(\"precaution\",case=False)|\n",
    "                        dataset.text.str.contains(\"safety\",case=False)|\n",
    "                        (\n",
    "                            dataset.text.str.contains(\"keep\",case=False)&\n",
    "                            dataset.text.str.contains(\"safe\",case=False)\n",
    "                        )\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"viruslife\"] = (\n",
    "                            (\n",
    "                                dataset.text.apply(fuzzy_match, pattern=\"(?:covid){e<=2}\")|\n",
    "                                dataset.text.str.contains(\"corona\",case=False)|\n",
    "                                dataset.text.str.contains(\"virus\",case=False)\n",
    "                            )&\n",
    "                            (\n",
    "                                dataset.text.str.contains(\"live|stay|survive\",case=False)\n",
    "                            )&\n",
    "                            (\n",
    "                                dataset.text.str.contains(\"on\",case=False)\n",
    "                            )\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"viruskill\"] = (\n",
    "                            (\n",
    "                                dataset.text.apply(fuzzy_match, pattern=\"(?:covid){e<=2}\")|\n",
    "                                dataset.text.str.contains(\"corona\",case=False)|\n",
    "                                dataset.text.str.contains(\"virus\",case=False)\n",
    "                            )&\n",
    "                            (\n",
    "                                dataset.text.str.contains(\"kills\",case=False)\n",
    "                            )\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"virusfight\"] = (\n",
    "                            (\n",
    "                                (\n",
    "                                    dataset.text.apply(fuzzy_match, pattern=\"(?:covid){e<=2}\")|\n",
    "                                    dataset.text.str.contains(\"corona\",case=False)|\n",
    "                                    dataset.text.str.contains(\"virus\",case=False)\n",
    "                                )&\n",
    "                                (\n",
    "                                    dataset.text.str.contains(\"fight\",case=False)\n",
    "                                )&\n",
    "                                (\n",
    "                                    dataset.text.str.contains(\"help\",case=False)\n",
    "                                )\n",
    "                            )|\n",
    "                            (\n",
    "                                dataset.text.str.contains(\"mask\",case=False)|\n",
    "                                dataset.text.str.contains(\"glove\",case=False)\n",
    "                            )\n",
    "                        ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"treatment\"] = (\n",
    "                        dataset.text.str.contains(\"treatment\",case=False)|\n",
    "                        dataset.text.str.contains(\"cure\",case=False)|\n",
    "                        dataset.text.str.contains(\"vaccine\",case=False)|\n",
    "                        dataset.text.str.contains(\"medic\",case=False)\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"incubation\"] = (\n",
    "                        dataset.text.str.contains(\"incubate\",case=False)|\n",
    "                        dataset.text.str.contains(\"incubation\",case=False)\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"nextsteps\"] = (\n",
    "                        dataset.text.str.contains(\"i have\",case=False) \n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"guideme\"] = (\n",
    "                        dataset.text.str.contains(\"if\",case=False)\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[\"hospital\"] = (\n",
    "# #                         dataset.text.str.contains(r\"\\bgo\\b\",case=False)&\n",
    "#                         (\n",
    "#                             dataset.text.str.contains(\"hospital\",case=False)|                            \n",
    "#                             dataset.text.str.contains(r\"\\bER\\b\",case=False)\n",
    "#                         )\n",
    "#                     ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dos and Donts\n",
    "dataset[\"lockdown\"] = (\n",
    "                        (\n",
    "                            (\n",
    "                                dataset.text.str.contains(\"go (?:on|to|for|out)\",case=False)|\n",
    "                                dataset.text.str.contains(\"walk\",case=False)\n",
    "                            )&\n",
    "                            (\n",
    "                                dataset.text.str.contains(\"allow\",case=False)|\n",
    "                                dataset.text.str.contains(\"can\",case=False)|\n",
    "                                dataset.text.str.contains(\"ok|okay\",case=False)|\n",
    "                                dataset.text.str.contains(\"should|shall\",case=False)\n",
    "                            )\n",
    "                        )|\n",
    "                        (\n",
    "                            dataset.text.str.contains(\"lockdown\",case=False)|\n",
    "                            dataset.text.str.contains(r\"\\bopen\\b\",case=False)|\n",
    "                            dataset.text.str.contains(r\"\\bclose\",case=False)\n",
    "                        )\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"infection\"] = (\n",
    "                        dataset.text.str.contains(\"infected\",case=False)|\n",
    "                        dataset.text.str.contains(\"infection\",case=False)\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"diff\"] = (\n",
    "                        dataset.text.str.contains(\"diff\",case=False)|\n",
    "                        dataset.text.apply(fuzzy_match, pattern=\"(?:distinguish){e<=3}\")\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"recover\"] = (\n",
    "                        dataset.text.str.contains(\"recover\",case=False)\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"test\"] = (\n",
    "                        dataset.text.str.contains(\"tested\",case=False)|\n",
    "                        dataset.text.str.contains(\"test\",case=False)\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"isolation\"] = (\n",
    "                            dataset.text.str.contains(r\"\\bisolat\",case=False)|\n",
    "                            dataset.text.str.contains(r\"\\bsocial dist\",case=False)\n",
    "                        ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"dangerisk\"] = (\n",
    "                            dataset.text.str.contains(\"dangerous\",case=False)|\n",
    "                            dataset.text.str.contains(\"risk\",case=False)\n",
    "                        ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"transmission\"] = (\n",
    "                            dataset.text.str.contains(\"transmi\",case=False)|\n",
    "                            dataset.text.str.contains(\"contract\",case=False)|\n",
    "                            dataset.text.str.contains(\"spread\",case=False)|\n",
    "                            dataset.text.apply(fuzzy_match, pattern=\"(?:airborne){e<=3}\")\n",
    "                        ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuzzy Matching of 'Symptom' keyword (accounting for spelling errors)\n",
    "dataset[\"symptom\"] = (\n",
    "                        dataset.text.apply(fuzzy_match, pattern=\"(?:symptom){1<=e<=3}\")\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"about\"] = (\n",
    "                        (\n",
    "                            dataset.text.apply(fuzzy_match, pattern=\"(?:whats|what (?:is|s))\")\n",
    "                        ) & \n",
    "                        (\n",
    "                            dataset.text.apply(fuzzy_match, pattern=\"(?:covid){e<=2}\")|\n",
    "                            dataset.text.str.contains(\"corona\",case=False)\n",
    "                        )\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"future\"] = (\n",
    "                        (\n",
    "                            (\n",
    "                                dataset.text.str.contains(\"how\",case=False) &\n",
    "                                dataset.text.str.contains(\"long\",case=False)\n",
    "                            )|\n",
    "                            dataset.text.str.contains(\"when\",case=False)\n",
    "                        )&\n",
    "                            dataset.text.str.contains(\"will\",case=False)&\n",
    "                        (\n",
    "                            dataset.text.str.contains(\"last|end|over|normal|done\",case=False)\n",
    "                        )\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"past\"] = (\n",
    "                        (\n",
    "                            dataset.text.str.contains(\"how|when|where\",case=False) \n",
    "                        )&\n",
    "                            dataset.text.str.contains(\"did\",case=False)&\n",
    "                        (\n",
    "                            dataset.text.str.contains(\"start|begin|began\",case=False)\n",
    "                        )\n",
    "                    ).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename(columns=new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col_name for col_name in dataset.columns.values.tolist() if \"-\" in col_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['situation-stats',\n",
       " 'covid-animals',\n",
       " 'personal-caution',\n",
       " 'covid-life',\n",
       " 'covid-kill',\n",
       " 'covid-fight',\n",
       " 'covid-med',\n",
       " 'covid-incubation',\n",
       " 'personal-symptoms',\n",
       " 'personal-whatif',\n",
       " 'situation-lockdown',\n",
       " 'covid-infection',\n",
       " 'covid-versus',\n",
       " 'covid-recovery',\n",
       " 'personal-testing',\n",
       " 'personal-isolation',\n",
       " 'covid-contagious',\n",
       " 'covid-transmission',\n",
       " 'covid-symptoms',\n",
       " 'covid-what',\n",
       " 'situation-future',\n",
       " 'situation-past']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"total\"] = dataset[features].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">situation-stats</th>\n",
       "      <th colspan=\"2\" halign=\"left\">covid-animals</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">situation-future</th>\n",
       "      <th colspan=\"8\" halign=\"left\">situation-past</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>549.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1058.0</td>\n",
       "      <td>0.078450</td>\n",
       "      <td>0.269005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1058.0</td>\n",
       "      <td>0.009452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1058.0</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>289.0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>0.044983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.157110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.218218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      situation-stats                                               \\\n",
       "                count      mean       std  min  25%  50%  75%  max   \n",
       "total                                                                \n",
       "0               549.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0   \n",
       "1              1058.0  0.078450  0.269005  0.0  0.0  0.0  0.0  1.0   \n",
       "2               289.0  0.058824  0.235702  0.0  0.0  0.0  0.0  1.0   \n",
       "3                80.0  0.025000  0.157110  0.0  0.0  0.0  0.0  1.0   \n",
       "4                21.0  0.047619  0.218218  0.0  0.0  0.0  0.0  1.0   \n",
       "5                 7.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0   \n",
       "6                 2.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0   \n",
       "11                1.0  0.000000       NaN  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      covid-animals            ... situation-future      situation-past  \\\n",
       "              count      mean  ...              75%  max          count   \n",
       "total                          ...                                        \n",
       "0             549.0  0.000000  ...              0.0  0.0          549.0   \n",
       "1            1058.0  0.009452  ...              0.0  1.0         1058.0   \n",
       "2             289.0  0.044983  ...              0.0  1.0          289.0   \n",
       "3              80.0  0.037500  ...              0.0  0.0           80.0   \n",
       "4              21.0  0.047619  ...              0.0  0.0           21.0   \n",
       "5               7.0  0.285714  ...              0.0  0.0            7.0   \n",
       "6               2.0  0.000000  ...              0.0  0.0            2.0   \n",
       "11              1.0  0.000000  ...              1.0  1.0            1.0   \n",
       "\n",
       "                                                  \n",
       "           mean     std  min  25%  50%  75%  max  \n",
       "total                                             \n",
       "0      0.000000  0.0000  0.0  0.0  0.0  0.0  0.0  \n",
       "1      0.003781  0.0614  0.0  0.0  0.0  0.0  1.0  \n",
       "2      0.000000  0.0000  0.0  0.0  0.0  0.0  0.0  \n",
       "3      0.000000  0.0000  0.0  0.0  0.0  0.0  0.0  \n",
       "4      0.000000  0.0000  0.0  0.0  0.0  0.0  0.0  \n",
       "5      0.000000  0.0000  0.0  0.0  0.0  0.0  0.0  \n",
       "6      0.000000  0.0000  0.0  0.0  0.0  0.0  0.0  \n",
       "11     0.000000     NaN  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[8 rows x 176 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby(\"total\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/designer1/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "dataset[\"cluster\"] = \"unclassified\"\n",
    "\n",
    "# For single features\n",
    "for col in features:\n",
    "    dataset[\"cluster\"][(dataset.total == 1) & (dataset[col] == True)] = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/designer1/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for col in features[::-1]:\n",
    "    dataset[\"cluster\"][(dataset.total > 1) & (dataset[col] == True)] = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rules based output saved to output/simple_2020-04-14_en.csv\n"
     ]
    }
   ],
   "source": [
    "path = f\"output/simple_{args.suffix}_{args.lang}.csv\"\n",
    "dataset.drop(features, axis=\"columns\").drop([\"text\",\"total\"], axis=\"columns\").to_csv(path)\n",
    "print(f\"Rules based output saved to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "covid-animals          29\n",
       "covid-contagious       47\n",
       "covid-fight            43\n",
       "covid-incubation       16\n",
       "covid-infection        66\n",
       "covid-kill              6\n",
       "covid-life             56\n",
       "covid-med              58\n",
       "covid-recovery         15\n",
       "covid-symptoms        227\n",
       "covid-transmission     55\n",
       "covid-versus            3\n",
       "covid-what            106\n",
       "personal-caution       55\n",
       "personal-isolation     39\n",
       "personal-symptoms     159\n",
       "personal-testing      103\n",
       "personal-whatif       187\n",
       "situation-future       19\n",
       "situation-lockdown     62\n",
       "situation-past          4\n",
       "situation-stats       103\n",
       "unclassified          549\n",
       "Name: question, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby(\"cluster\")[\"question\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length analysis for situations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA and AHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dataset[dataset.cluster==\"unclassified\"][[\"question\", \"cluster\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "stopwords_list = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def bulk_tokenizer(texts):\n",
    "#      return [[wn_lemmatizer.lemmatize(token) for token in nltk.word_tokenize(text)] for text in texts]\n",
    "     return [nltk.word_tokenize(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43 clusters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ahc_label\n",
       "31     2\n",
       "21     3\n",
       "36     3\n",
       "41     3\n",
       "40     4\n",
       "38     4\n",
       "34     4\n",
       "29     4\n",
       "23     4\n",
       "17     4\n",
       "39     5\n",
       "42     5\n",
       "4      6\n",
       "20     6\n",
       "3      7\n",
       "16     7\n",
       "19     7\n",
       "30     7\n",
       "26     7\n",
       "0      8\n",
       "15     8\n",
       "5      8\n",
       "28     8\n",
       "35     9\n",
       "27     9\n",
       "12    10\n",
       "8     10\n",
       "24    10\n",
       "14    11\n",
       "37    13\n",
       "33    13\n",
       "18    14\n",
       "9     15\n",
       "13    18\n",
       "25    18\n",
       "11    19\n",
       "1     21\n",
       "6     22\n",
       "7     22\n",
       "2     23\n",
       "10    26\n",
       "22    33\n",
       "32    36\n",
       "Name: question, dtype: int64"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.n_topics = 15\n",
    "args.dist_thresh = 0.7\n",
    "model = utils.text.representation.LSI(args, tokenizer=bulk_tokenizer)\n",
    "d[\"embedding\"] = model.generate_embedding(d.question, returnarray=False)\n",
    "\n",
    "# Cluster\n",
    "X = pd.DataFrame(d[\"embedding\"].values.tolist(), index= d.index).to_numpy()\n",
    "clustering = AgglomerativeClustering(n_clusters=None, compute_full_tree=True, distance_threshold=args.dist_thresh).fit(X)\n",
    "d[\"ahc_label\"] = clustering.labels_\n",
    "\n",
    "# Misc.\n",
    "args.n_clusters = len(d[\"ahc_label\"].unique())\n",
    "print(f\"Found {args.n_clusters} clusters\")\n",
    "d.groupby(\"ahc_label\")[\"question\"].count().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    43.000000\n",
       "mean     11.069767\n",
       "std       8.209737\n",
       "min       2.000000\n",
       "25%       5.000000\n",
       "50%       8.000000\n",
       "75%      14.500000\n",
       "max      36.000000\n",
       "Name: question, dtype: float64"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.groupby(\"ahc_label\")[\"question\"].count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for label in d.ahc_label.unique():\n",
    "#     print(f\"\\ncluster #{label}, count - {len(d[d.ahc_label==label])}\")\n",
    "#     print(d[d.ahc_label==label][:10].question.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.join(d[\"ahc_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AHC on top of rule based output saved to output/simpleLsa_15n0.7dt_2020-03-27T19_12_30.866993Z.csv\n"
     ]
    }
   ],
   "source": [
    "path = f\"output/simpleLsa_{args.n_topics}n{args.dist_thresh}dt_{args.suffix}.csv\"\n",
    "dataset.to_csv(path)\n",
    "print(f\"AHC on top of rule based output saved to {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
